{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Foundation\n",
    "import torch\n",
    "from tokenizer import Tokenizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch version 2.0.1+cu118\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using PyTorch version {torch.__version__}\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 1e-2\n",
    "VOCAB_SIZE = 128\n",
    "BLOCK_SIZE = 128\n",
    "EMBD_SIZE = 256\n",
    "NUM_HEADS = 16\n",
    "NUM_BLOCKS = 16\n",
    "DROPOUT = 0.1\n",
    "WARMUP_STEPS = 4000\n",
    "\n",
    "\n",
    "CSV_DIR = \"/media/starsystem/baby2/Foundation/\"\n",
    "MODEL_SAVE_DIR = \"/media/starsystem/baby2/Foundation/\"\n",
    "MODEL_SAVE_NAME = \"Foundation.pt\"\n",
    "CSV_NAME = \"Foundation.csv\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tokenizer.Tokenizer at 0x7fadf39f92a0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Foundation(num_blocks = NUM_BLOCKS, num_heads = NUM_HEADS, vocab_size=VOCAB_SIZE, block_size=BLOCK_SIZE, embd_size=EMBD_SIZE, dropout = DROPOUT).to(device)\n",
    "\n",
    "# model = torch.compile(model,mode = \"reduce-overhead\")\n",
    "model.load_state_dict(torch.load(MODEL_SAVE_DIR + MODEL_SAVE_NAME))\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.load(\"tokenizer2.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "CHARD II:\n",
      "What is thy name? what is thy name? why? what is thy\n",
      "name? what is thy name? why? what is thy name?\n",
      "\n",
      "WARWICK:\n",
      "Then then the king? Why, then thou art not so bold.\n",
      "\n",
      "QUEEN:\n",
      "Thou art a man that thou hast worn the world.\n",
      "\n",
      "KING RICHARD II:\n",
      "Why, thou hast not a word to say 'silver Richard!'\n",
      "\n",
      "QUEEN:\n",
      "By God's son, thou hast not so foul a thousand that.\n",
      "\n",
      "YORK:\n",
      "I would thou wert a thousand that I love thee.\n",
      "\n",
      "YORK:\n",
      "I would thou wert a thousand that I had a thousand\n",
      "that I would say 'tis thus that word that I had wont.\n",
      "\n",
      "ROMEO:\n",
      "I would thou wert too sad, that I would were too shrift\n",
      "To see the sea that I have proved thee for thee!\n",
      "\n",
      "JULIET:\n",
      "I would thou wert too much that I were seen,\n",
      "And thou shalt still be seen to be a shame.\n",
      "\n",
      "ROMEO:\n",
      "I would thou wilt be satisfied to the world.\n",
      "\n",
      "JULIET:\n",
      "I would thou wert too sad, that thou hast shown thee that\n",
      "Thou wert a man too much a man, thou wouldst thy master\n",
      "with thy sweet power to thy heart's alliance.\n",
      "\n",
      "ROMEO:\n",
      "I would thou wert too much that thou h\n"
     ]
    }
   ],
   "source": [
    "start_text = \"C\"\n",
    "new_tokens = 1000\n",
    "current_tokens = tokenizer.encode(start_text)\n",
    "print(len(current_tokens))\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for _ in range(new_tokens):\n",
    "        x = torch.tensor(current_tokens[-BLOCK_SIZE:]).to(torch.int64).to(device)\n",
    "        x = x.view(1, -1)\n",
    "        y = model(x, return_loss = False)\n",
    "        y = y[0, -1, :]\n",
    "        y = y.argmax().item()\n",
    "        current_tokens.append(y)\n",
    "\n",
    "print(tokenizer.decode(current_tokens))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
